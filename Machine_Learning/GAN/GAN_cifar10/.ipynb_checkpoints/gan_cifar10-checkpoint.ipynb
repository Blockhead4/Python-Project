{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN_CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 32\n",
    "        self.img_cols = 32\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(384 * 8 * 8, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((8, 8, 384)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(384, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(192, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = cifar10.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "#         X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 5, 5, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 5, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 5, 5, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 6401      \n",
      "=================================================================\n",
      "Total params: 396,609\n",
      "Trainable params: 395,713\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 6144)              620544    \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2 (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 8, 8, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 8, 8, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2 (None, 16, 16, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 16, 16, 192)       663744    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 16, 16, 192)       768       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 32, 32, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 32, 32, 3)         5187      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 32, 32, 3)         0         \n",
      "=================================================================\n",
      "Total params: 2,619,267\n",
      "Trainable params: 2,618,115\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jwp\\Anaconda3\\envs\\py_ml\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "C:\\Users\\Jwp\\Anaconda3\\envs\\py_ml\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 1.300508, acc.: 23.44%] [G loss: 0.506444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jwp\\Anaconda3\\envs\\py_ml\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [D loss: 0.887773, acc.: 53.12%] [G loss: 0.763697]\n",
      "2 [D loss: 0.929825, acc.: 45.31%] [G loss: 1.016110]\n",
      "3 [D loss: 1.021521, acc.: 35.94%] [G loss: 0.813633]\n",
      "4 [D loss: 0.817555, acc.: 46.88%] [G loss: 1.022964]\n",
      "5 [D loss: 0.733229, acc.: 57.81%] [G loss: 1.013387]\n",
      "6 [D loss: 0.511916, acc.: 75.00%] [G loss: 0.968335]\n",
      "7 [D loss: 0.674498, acc.: 65.62%] [G loss: 0.989262]\n",
      "8 [D loss: 0.949077, acc.: 50.00%] [G loss: 1.246673]\n",
      "9 [D loss: 0.956187, acc.: 45.31%] [G loss: 0.882248]\n",
      "10 [D loss: 0.713398, acc.: 62.50%] [G loss: 0.528749]\n",
      "11 [D loss: 0.762828, acc.: 56.25%] [G loss: 0.362372]\n",
      "12 [D loss: 0.801314, acc.: 51.56%] [G loss: 0.271804]\n",
      "13 [D loss: 0.483293, acc.: 79.69%] [G loss: 0.537735]\n",
      "14 [D loss: 0.499480, acc.: 71.88%] [G loss: 0.678303]\n",
      "15 [D loss: 0.545212, acc.: 68.75%] [G loss: 0.937405]\n",
      "16 [D loss: 0.705157, acc.: 57.81%] [G loss: 1.072109]\n",
      "17 [D loss: 0.410160, acc.: 78.12%] [G loss: 1.232793]\n",
      "18 [D loss: 0.471922, acc.: 79.69%] [G loss: 1.062516]\n",
      "19 [D loss: 0.401650, acc.: 81.25%] [G loss: 0.814922]\n",
      "20 [D loss: 0.338742, acc.: 90.62%] [G loss: 1.295917]\n",
      "21 [D loss: 0.395937, acc.: 79.69%] [G loss: 1.845409]\n",
      "22 [D loss: 1.398467, acc.: 43.75%] [G loss: 3.171515]\n",
      "23 [D loss: 0.725256, acc.: 53.12%] [G loss: 2.920691]\n",
      "24 [D loss: 0.480174, acc.: 75.00%] [G loss: 1.255907]\n",
      "25 [D loss: 0.517351, acc.: 75.00%] [G loss: 0.259122]\n",
      "26 [D loss: 0.321269, acc.: 92.19%] [G loss: 0.280973]\n",
      "27 [D loss: 0.195814, acc.: 96.88%] [G loss: 0.328142]\n",
      "28 [D loss: 0.213193, acc.: 93.75%] [G loss: 0.405103]\n",
      "29 [D loss: 0.252406, acc.: 92.19%] [G loss: 0.656044]\n",
      "30 [D loss: 0.311102, acc.: 90.62%] [G loss: 1.307179]\n",
      "31 [D loss: 0.279060, acc.: 92.19%] [G loss: 1.212491]\n",
      "32 [D loss: 0.114836, acc.: 98.44%] [G loss: 1.205450]\n",
      "33 [D loss: 0.233358, acc.: 92.19%] [G loss: 0.578760]\n",
      "34 [D loss: 0.297747, acc.: 89.06%] [G loss: 0.776611]\n",
      "35 [D loss: 0.188065, acc.: 93.75%] [G loss: 1.395542]\n",
      "36 [D loss: 0.546510, acc.: 71.88%] [G loss: 1.474901]\n",
      "37 [D loss: 0.491872, acc.: 71.88%] [G loss: 1.796913]\n",
      "38 [D loss: 0.388878, acc.: 76.56%] [G loss: 1.006111]\n",
      "39 [D loss: 0.348500, acc.: 87.50%] [G loss: 0.651322]\n",
      "40 [D loss: 0.383552, acc.: 81.25%] [G loss: 0.483820]\n",
      "41 [D loss: 0.141669, acc.: 98.44%] [G loss: 0.196017]\n",
      "42 [D loss: 0.108996, acc.: 98.44%] [G loss: 0.052691]\n",
      "43 [D loss: 0.141954, acc.: 96.88%] [G loss: 0.103390]\n",
      "44 [D loss: 0.096682, acc.: 96.88%] [G loss: 0.060592]\n",
      "45 [D loss: 0.128734, acc.: 95.31%] [G loss: 0.158711]\n",
      "46 [D loss: 0.107195, acc.: 96.88%] [G loss: 0.183868]\n",
      "47 [D loss: 0.087390, acc.: 100.00%] [G loss: 0.358392]\n",
      "48 [D loss: 0.090441, acc.: 98.44%] [G loss: 0.269087]\n",
      "49 [D loss: 0.067980, acc.: 98.44%] [G loss: 0.337960]\n",
      "50 [D loss: 0.147834, acc.: 96.88%] [G loss: 0.502998]\n",
      "51 [D loss: 0.112881, acc.: 98.44%] [G loss: 0.585181]\n",
      "52 [D loss: 0.130680, acc.: 96.88%] [G loss: 0.753535]\n",
      "53 [D loss: 0.387866, acc.: 82.81%] [G loss: 2.074906]\n",
      "54 [D loss: 0.538646, acc.: 70.31%] [G loss: 2.642571]\n",
      "55 [D loss: 1.484298, acc.: 32.81%] [G loss: 1.849027]\n",
      "56 [D loss: 0.765729, acc.: 65.62%] [G loss: 0.554579]\n",
      "57 [D loss: 0.604475, acc.: 75.00%] [G loss: 0.169121]\n",
      "58 [D loss: 0.220726, acc.: 92.19%] [G loss: 0.241076]\n",
      "59 [D loss: 0.131777, acc.: 98.44%] [G loss: 0.089899]\n",
      "60 [D loss: 0.190769, acc.: 96.88%] [G loss: 0.137289]\n",
      "61 [D loss: 0.069927, acc.: 100.00%] [G loss: 0.327583]\n",
      "62 [D loss: 0.144015, acc.: 96.88%] [G loss: 0.366166]\n",
      "63 [D loss: 0.230912, acc.: 93.75%] [G loss: 0.319135]\n",
      "64 [D loss: 0.257362, acc.: 89.06%] [G loss: 0.683530]\n",
      "65 [D loss: 0.180492, acc.: 92.19%] [G loss: 0.643656]\n",
      "66 [D loss: 0.530590, acc.: 75.00%] [G loss: 1.433301]\n",
      "67 [D loss: 0.463251, acc.: 82.81%] [G loss: 0.847529]\n",
      "68 [D loss: 0.393850, acc.: 81.25%] [G loss: 1.282674]\n",
      "69 [D loss: 0.528467, acc.: 73.44%] [G loss: 2.260632]\n",
      "70 [D loss: 0.506873, acc.: 78.12%] [G loss: 1.961005]\n",
      "71 [D loss: 0.373091, acc.: 87.50%] [G loss: 2.367306]\n",
      "72 [D loss: 0.494891, acc.: 71.88%] [G loss: 2.324913]\n",
      "73 [D loss: 0.615780, acc.: 70.31%] [G loss: 2.509143]\n",
      "74 [D loss: 0.865864, acc.: 54.69%] [G loss: 1.285315]\n",
      "75 [D loss: 0.701999, acc.: 59.38%] [G loss: 1.263907]\n",
      "76 [D loss: 0.643053, acc.: 67.19%] [G loss: 1.319231]\n",
      "77 [D loss: 0.330642, acc.: 87.50%] [G loss: 1.188346]\n",
      "78 [D loss: 0.461644, acc.: 79.69%] [G loss: 1.554530]\n",
      "79 [D loss: 0.431351, acc.: 78.12%] [G loss: 1.336921]\n",
      "80 [D loss: 0.918472, acc.: 54.69%] [G loss: 3.104461]\n",
      "81 [D loss: 0.428975, acc.: 78.12%] [G loss: 3.511333]\n",
      "82 [D loss: 0.583709, acc.: 70.31%] [G loss: 2.285686]\n",
      "83 [D loss: 0.292748, acc.: 90.62%] [G loss: 2.770835]\n",
      "84 [D loss: 0.242003, acc.: 95.31%] [G loss: 2.994972]\n",
      "85 [D loss: 0.361733, acc.: 84.38%] [G loss: 1.862673]\n",
      "86 [D loss: 0.299738, acc.: 89.06%] [G loss: 2.443550]\n",
      "87 [D loss: 0.186331, acc.: 93.75%] [G loss: 3.301762]\n",
      "88 [D loss: 0.172381, acc.: 95.31%] [G loss: 3.249794]\n",
      "89 [D loss: 0.287545, acc.: 84.38%] [G loss: 2.418239]\n",
      "90 [D loss: 0.469546, acc.: 79.69%] [G loss: 3.776118]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    dcgan.train(epochs=4000, batch_size=32, save_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_ML",
   "language": "python",
   "name": "py_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
